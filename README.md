Objective was to identify and benchmark several advanced convolutional neural network (CNN)architectures for distinguishing the full ASL alphabet, and then to embed the mostaccurate model into a live recognition stream driven by a webcam and MediaPipe hand tracking. 
This study trained and fine-tuned a suite of pre-trained models like VGG16, ResNet50, InceptionV3, DenseNet201, and MobileNetV2 alongside a custom CNN on a balanced ASL dataset of 27 handshape classes.

## ğŸ”— Resources

### ğŸ“Š Dataset
The dataset used in this project is publicly available on Kaggle:  
ğŸ‘‰ [Kaggle Dataset Link](https://www.kaggle.com/datasets/grassknoted/asl-alphabet/data)

### ğŸ¤– Trained Models
- VGG16
- ResNet50
- DenseNet201
- InceptionV3
- MobileNetV2
- Custom CNN
The pretrained model files (`.h5`, `.pkl`) are hosted on Kaggle:  
ğŸ‘‰ [Model Download Link](https://www.kaggle.com/models/siddhantbahadkar/huge_models)

## âš™ï¸ Configuration
Configuration files are available in the `config/` folder.

## ğŸ“ˆ Results
- Validation Accuracy: 93.18%
- Test Accuracy: 98.77%  
Visual results and confusion matrix are included in the notebook.

## ğŸ§© Tools Used
- Python, TensorFlow, Keras, OpenCV
- Matplotlib, Seaborn
- Jupyter Notebook

## ğŸ—‚ï¸ Repository Structure
